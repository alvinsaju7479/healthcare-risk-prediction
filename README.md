# ğŸ¥ Healthcare Readmission Risk Prediction

An **end-to-end healthcare risk prediction system** that predicts the likelihood of **30-day hospital readmission** using structured clinical data.

This project demonstrates:
- Production-style ML pipelines
- Feature engineering & model training
- **Fairness evaluation across demographic groups**
- **Model explainability for clinical interpretability**

> âš ï¸ This project is for **educational and analytical purposes only** and is **not intended for clinical decision-making**.

---

## ğŸ¯ Problem Statement

Hospital readmissions within 30 days are costly and often preventable.  
Accurately identifying **high-risk patients** can help healthcare providers:
- Improve patient outcomes
- Optimize resource allocation
- Reduce avoidable readmissions

This project formulates the problem as a **binary classification task**:
> Predict whether a patient will be readmitted within 30 days.

---

## ğŸ“Š Dataset

- **Source:** Diabetes 130-US Hospitals Readmission Dataset (public)
- **Size:** ~101,000 patient encounters
- **Features:** Demographics, diagnoses, procedures, medications, lab tests
- **Target:**  
  `1` â†’ Readmitted within 30 days  
  `0` â†’ Not readmitted within 30 days

âš ï¸ The dataset is **not included** in this repository.  
See `data/README.md` for download instructions.

---

## ğŸ—ï¸ Project Architecture
```text
healthcare-risk-prediction/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data/ # Data loading & splitting
â”‚ â”œâ”€â”€ features/ # Feature engineering
â”‚ â”œâ”€â”€ models/ # Training, evaluation, explainability
â”‚
â”œâ”€â”€ data/ # Raw & processed data (ignored in git)
â”œâ”€â”€ models/ # Trained models (ignored in git)
â”œâ”€â”€ reports/ # Evaluation reports & figures
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§  Modeling Approach

- **Model:** Logistic Regression (class-weighted)
- **Preprocessing:**
  - Numeric: median imputation + standard scaling
  - Categorical: mode imputation + one-hot encoding
- **Validation:** Train / validation / test split
- **Metric:** ROC-AUC (primary)

---

## âœ… Results

### ğŸ“ˆ Performance
Detailed model performance metrics:
- ROC-AUC
- Precision / Recall
- Confusion Matrix

â¡ï¸ See: [`reports/performance_report.md`](reports/performance_report.md)

---

### âš–ï¸ Fairness Evaluation

Fairness was evaluated across key sensitive attributes:
- **Gender**
- **Age group**
- **Race**

Metrics used:
- Selection Rate
- True Positive Rate (TPR)

â¡ï¸ See: [`reports/fairness_report.md`](reports/fairness_report.md)

---

### ğŸ” Explainability

Global explainability was achieved using **permutation importance**, showing which features most influence predictions.

![Global Feature Importance](reports/figures/global_feature_importance.png)

This helps ensure the model remains **interpretable and auditable**, which is critical in healthcare applications.

---

## ğŸ§¾ Model Card

A structured **Model Card** documenting:
- Intended use
- Metrics
- Fairness considerations
- Limitations & ethical risks

â¡ï¸ See: [`reports/model_card.md`](reports/model_card.md)

---

## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Set up environment
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .\.venv\Scripts\activate
pip install -r requirements.txt
```
### 2ï¸âƒ£ Place dataset
```bash
data/raw/diabetic_data.csv
```
### 3ï¸âƒ£ Run pipeline
```bash
python -m src.data.make_dataset
python -m src.data.split
python -m src.models.train
python -m src.models.evaluate
python -m src.models.performance
python -m src.models.explain_global

```
